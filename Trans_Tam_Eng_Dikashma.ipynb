{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# File paths for Tamil and English datasets\n",
        "tamil_file_path = \"/content/drive/MyDrive/Colab Notebooks/en-ta/train.ta\"\n",
        "english_file_path = \"/content/drive/MyDrive/Colab Notebooks/en-ta/train.en\"\n",
        "\n",
        "# Load Tamil sentences from file\n",
        "with open(tamil_file_path, \"r\", encoding=\"utf-8\") as tamil_file:\n",
        "    tamil_sentences = tamil_file.readlines()\n",
        "\n",
        "# Load English sentences from file\n",
        "with open(english_file_path, \"r\", encoding=\"utf-8\") as english_file:\n",
        "    english_sentences = english_file.readlines()\n",
        "\n",
        "# Check data consistency\n",
        "assert len(tamil_sentences) == len(english_sentences), \"Number of sentences in Tamil and English datasets should match\"\n",
        "\n",
        "# Strip newline characters from the end of sentences\n",
        "tamil_sentences = [sentence.strip() for sentence in tamil_sentences]\n",
        "english_sentences = [sentence.strip() for sentence in english_sentences]\n",
        "\n",
        "# Combine datasets\n",
        "combined_dataset = list(zip(tamil_sentences, english_sentences))\n",
        "\n",
        "# Example entries in the combined dataset\n",
        "for tamil, english in combined_dataset[67:69]:\n",
        "    print(\"Tamil:\", tamil)\n",
        "    print(\"English:\", english)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdA8_m2613B7",
        "outputId": "26ed3e6c-50e1-42a9-e9e4-fc377e491751"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Tamil: இதனால் தற்போது வரை தண்ணீா் வீணாகச் செல்கிறது.\n",
            "English: As a result, water goes waste.\n",
            "\n",
            "Tamil: புத்தகத்தில் 33 - லிருந்து 37 - ம் அதிகாரங்களைக் காண்க.\n",
            "English: For an in - depth study of the prophecy of Revelation regarding Babylon the Great, see chapters 33 to 37 of the book Revelation Its Grand Climax At Hand!, published in 1988 by the Watchtower Bible and Tract Society of New York, Inc.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wkOx2JB08x4B"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to sample a subset of data\n",
        "def sample_data(tamil_sentences, english_sentences, sample_size):\n",
        "    tamil_sentences_sample = tamil_sentences[:sample_size]\n",
        "    english_sentences_sample = english_sentences[:sample_size]\n",
        "    return tamil_sentences_sample, english_sentences_sample"
      ],
      "metadata": {
        "id": "hMlTuYtA_fLA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Tamil and English sentences from files\n",
        "tamil_file_path = \"/content/drive/MyDrive/Colab Notebooks/en-ta/train.ta\"\n",
        "english_file_path = \"/content/drive/MyDrive/Colab Notebooks/en-ta/train.en\""
      ],
      "metadata": {
        "id": "hAU0Xuqs_fOg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(tamil_file_path, \"r\", encoding=\"utf-8\") as tamil_file:\n",
        "    tamil_sentences = tamil_file.readlines()\n",
        "\n",
        "with open(english_file_path, \"r\", encoding=\"utf-8\") as english_file:\n",
        "    english_sentences = english_file.readlines()"
      ],
      "metadata": {
        "id": "zi5T5E8W_fbR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample a subset of data\n",
        "sample_size = 10000\n",
        "tamil_sentences_sample, english_sentences_sample = sample_data(tamil_sentences, english_sentences, sample_size)"
      ],
      "metadata": {
        "id": "5tv03_zv_fek"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing data\n",
        "def tf_encode(tamil, english):\n",
        "    # Tokenizing and pad sequences\n",
        "    tamil = tamil_tokenizer.texts_to_sequences(tamil)\n",
        "    tamil = tf.keras.preprocessing.sequence.pad_sequences(tamil, padding='post')\n",
        "\n",
        "    english = english_tokenizer.texts_to_sequences(english)\n",
        "    english = tf.keras.preprocessing.sequence.pad_sequences(english, padding='post')\n",
        "\n",
        "    return tamil, english"
      ],
      "metadata": {
        "id": "3nKvZleY_9QT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining tokenizer\n",
        "tamil_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tamil_tokenizer.fit_on_texts(tamil_sentences_sample)\n",
        "english_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "english_tokenizer.fit_on_texts(english_sentences_sample)"
      ],
      "metadata": {
        "id": "-Ju7p_we_9TC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the tf_encode function to the dataset\n",
        "tamil_dataset, english_dataset = tf_encode(tamil_sentences_sample, english_sentences_sample)"
      ],
      "metadata": {
        "id": "dE8oNN_4_9Wc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the start and end token to the target sequences\n",
        "english_dataset = np.insert(english_dataset, 0, 0, axis=1)\n",
        "english_dataset = np.insert(english_dataset, len(english_dataset[0]), 0, axis=1)"
      ],
      "metadata": {
        "id": "0_MWwSQ_AHXY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating TensorFlow Dataset\n",
        "BUFFER_SIZE = len(tamil_dataset)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((tamil_dataset, english_dataset)).shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "jJYyKHVPAHg-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Defining helper functions for creating masks\n",
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    # Add extra dimensions to add the padding\n",
        "    # to the attention logits.\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)\n",
        "\n",
        "def create_masks(inp, tar):\n",
        "    # Encoder padding mask\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 2nd attention block in the decoder.This padding mask is used to mask the encoder outputs.\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 1st attention block in the decoder. It is used to pad and mask future tokens in the input received by the decoder.\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "metadata": {
        "id": "ouEKj-2NAHss"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the scaled dot product attention function\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "Ck2b0UMsB2xA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the multi-head attention function\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        assert d_model % self.num_heads == 0\n",
        "        self.depth = d_model // self.num_heads\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "tMzCrOm-B2-Q"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the multi-head attention function\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        assert d_model % self.num_heads == 0\n",
        "        self.depth = d_model // self.num_heads\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "3K8eUixsC57T"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                                self.d_model)\n",
        "\n",
        "        self.enc_layers = [TransformerEncoderLayer(d_model, num_heads, dff, rate)\n",
        "                           for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # adding embedding and position encoding.\n",
        "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "cguDrLgSC8XY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(TransformerDecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model)\n",
        "        ])\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "metadata": {
        "id": "16002_NkC8kr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [TransformerDecoderLayer(d_model, num_heads, dff, rate)\n",
        "                           for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                                   look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        return x, attention_weights"
      ],
      "metadata": {
        "id": "Nr2US66pC8ui"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Transformer model\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = TransformerEncoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "        self.decoder = TransformerDecoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "        final_output = self.final_layer(dec_output)\n",
        "        return final_output, attention_weights"
      ],
      "metadata": {
        "id": "tB_qEdacDbg3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the training loop\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = Transformer(inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, Transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, Transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)"
      ],
      "metadata": {
        "id": "YwmEeamXE-ti"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Instantiating the Transformer model\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "num_heads = 8\n",
        "dff = 512\n",
        "input_vocab_size = len(tamil_tokenizer.word_index) + 1\n",
        "target_vocab_size = len(english_tokenizer.word_index) + 1\n",
        "dropout_rate = 0.1\n",
        "\n",
        "# Defining the maximum position encoding for input and target sequences\n",
        "pe_input = 1000\n",
        "pe_target = 1000\n",
        "\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size,pe_input=pe_input,pe_target=pe_target,rate=dropout_rate)\n",
        "\n"
      ],
      "metadata": {
        "id": "ntXKohMrFPhL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define loss function and optimizer\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "OWlS77AbFRMF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "GyB8L7v1FRPe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define metrics\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
      ],
      "metadata": {
        "id": "N2OmZO5qFdpk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Training loop\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "\n",
        "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "    '''\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Define the training step function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = Transformer(inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, Transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, Transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)\n",
        "\n"
      ],
      "metadata": {
        "id": "nc6KoPbrFdtB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "\n",
        "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "        train_step(inp, tar)\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "LwElYudSKJ3R",
        "outputId": "ab5bdbb4-848a-4207-fa19-817e20d5ce76"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Transformer.__init__() missing 2 required positional arguments: 'pe_input' and 'pe_target'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-b31a9d87ea7c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-3f884dd28993>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(inp, tar)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtar_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Transformer.__init__() missing 2 required positional arguments: 'pe_input' and 'pe_target'"
          ]
        }
      ]
    }
  ]
}